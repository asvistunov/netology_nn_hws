{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import torchvision as tv \n",
    "\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrsvistunov/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#loading dataset\n",
    "BATCH_SIZE = 256 \n",
    "\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for batch in train:\n",
    "    print(type(batch[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 2048),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.BatchNorm1d(2048),\n",
    "    torch.nn.Linear(2048, 1024),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.BatchNorm1d(1024),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.006)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs + 1):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0. \n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(axis=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0. \n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(axis=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        \n",
    "        print('ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}'.format(\n",
    "        ep, time.time() - start, train_loss / train_iters, train_acc / train_passed, \n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "             )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 27.509, train_loss: 0.49582242306242597, train_acc: 0.8196666666666667, test_loss: 0.47002851627767084, test_acc: 0.8253\n",
      "ep: 1, taked: 26.712, train_loss: 0.3735350763544123, train_acc: 0.86125, test_loss: 0.46261726804077624, test_acc: 0.8284\n",
      "ep: 2, taked: 27.134, train_loss: 0.3417379951223414, train_acc: 0.8731166666666667, test_loss: 0.42383682560175656, test_acc: 0.8518\n",
      "ep: 3, taked: 27.088, train_loss: 0.3190451115369797, train_acc: 0.88165, test_loss: 0.42140161748975513, test_acc: 0.8552\n",
      "ep: 4, taked: 27.929, train_loss: 0.3018202029010083, train_acc: 0.8883, test_loss: 0.44944524988532064, test_acc: 0.8484\n",
      "ep: 5, taked: 27.686, train_loss: 0.28500760159593946, train_acc: 0.8940833333333333, test_loss: 0.7891166875138879, test_acc: 0.8631\n",
      "ep: 6, taked: 27.471, train_loss: 0.2725510811552088, train_acc: 0.8987166666666667, test_loss: 0.5847410719841719, test_acc: 0.8615\n",
      "ep: 7, taked: 28.607, train_loss: 0.26146716316963764, train_acc: 0.9033166666666667, test_loss: 2.0505405587609857, test_acc: 0.8658\n",
      "ep: 8, taked: 27.800, train_loss: 0.2583620871635193, train_acc: 0.9035166666666666, test_loss: 2.476702369330451, test_acc: 0.8687\n",
      "ep: 9, taked: 27.938, train_loss: 0.24448629579645523, train_acc: 0.9081666666666667, test_loss: 3.070748813636601, test_acc: 0.8698\n",
      "ep: 10, taked: 27.178, train_loss: 0.2337143232847782, train_acc: 0.9128166666666667, test_loss: 1.1261285125277936, test_acc: 0.8752\n",
      "ep: 11, taked: 27.331, train_loss: 0.23823225073357845, train_acc: 0.9103833333333333, test_loss: 3.628434787876904, test_acc: 0.868\n",
      "ep: 12, taked: 27.445, train_loss: 0.21841357505701958, train_acc: 0.9181166666666667, test_loss: 7.189946713298559, test_acc: 0.8803\n",
      "ep: 13, taked: 27.269, train_loss: 0.2040702319525658, train_acc: 0.9230333333333334, test_loss: 9.6881740023382, test_acc: 0.88\n",
      "ep: 14, taked: 27.287, train_loss: 0.19352112057361198, train_acc: 0.9271333333333334, test_loss: 7.814478245284408, test_acc: 0.8792\n",
      "ep: 15, taked: 27.388, train_loss: 0.18368532185224776, train_acc: 0.9300166666666667, test_loss: 2.5323267679661514, test_acc: 0.8727\n",
      "ep: 16, taked: 28.357, train_loss: 0.18010786654467278, train_acc: 0.9317333333333333, test_loss: 3.1478385160677136, test_acc: 0.8748\n",
      "ep: 17, taked: 27.251, train_loss: 0.17741508154158897, train_acc: 0.9326833333333333, test_loss: 4.467611726932228, test_acc: 0.8788\n",
      "ep: 18, taked: 27.288, train_loss: 0.16619834693822455, train_acc: 0.9366166666666667, test_loss: 5.532436490058899, test_acc: 0.8757\n",
      "ep: 19, taked: 27.479, train_loss: 0.2083970547990596, train_acc: 0.9210166666666667, test_loss: 18.932390374108216, test_acc: 0.8853\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn([1, 1, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2906,  0.4880, -0.6926, -2.3897,  0.3771, -0.6239,  0.1224, -0.8395],\n",
       "        [-1.3610, -0.1927, -0.3939,  1.6888,  1.4555,  0.0314, -0.1710, -0.7583],\n",
       "        [ 1.1036, -0.5579,  0.0708,  2.0836,  1.0304,  0.8713, -1.3628, -0.5483],\n",
       "        [ 1.7149, -0.3713, -0.9609,  0.2689, -0.2862, -1.7155,  0.4723, -1.2409],\n",
       "        [-1.2308, -0.1191, -0.4264,  0.0873,  0.7643, -2.0886,  0.3779, -1.0321],\n",
       "        [-1.7581, -0.7506,  0.1579, -0.2088,  0.2930, -0.0335, -1.1956, -0.1251],\n",
       "        [-0.4938,  0.2531, -0.4120, -0.4505, -0.5430, -0.5885, -1.1072, -0.4508],\n",
       "        [ 0.6124, -0.7455, -0.2885, -0.2311,  1.3411, -0.6279,  0.7520,  1.0228]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  1.,  2.,  3.,  0.],\n",
      "        [ 0.,  4.,  5.,  6.,  7.,  0.],\n",
      "        [ 0.,  8.,  9., 10., 11.,  0.],\n",
      "        [ 0., 12., 13., 14., 15.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "def show_prety(matrix):\n",
    "    torch.set_printoptions(profile=\"short\")\n",
    "    print(matrix)\n",
    "    torch.set_printoptions(profile=\"default\")\n",
    "    return None \n",
    "\n",
    "show_prety(torch.nn.functional.pad(X[0][0], pad=[1, 1,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "conv2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "conv2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 8, 8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "X = torch.randn([1, 3, 8, 8])\n",
    "conv2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 3, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  2.,  3.,  0.],\n",
      "        [ 0.,  4.,  5.,  6.,  7.,  0.],\n",
      "        [ 0.,  8.,  9., 10., 11.,  0.],\n",
      "        [ 0., 12., 13., 14., 15.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(16).reshape([1, 1, 4, 4]).float()\n",
    "\n",
    "show_prety(torch.nn.functional.pad(X[0][0], pad=[1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = torch.nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1111,  2.0000,  2.6667,  2.0000],\n",
       "          [ 3.0000,  5.0000,  6.0000,  4.3333],\n",
       "          [ 5.6667,  9.0000, 10.0000,  7.0000],\n",
       "          [ 4.6667,  7.3333,  8.0000,  5.5556]]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = torch.nn.AvgPool2d(3, padding=(1, 1), stride=1)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.MaxPool2d(2, stride=2),\n",
    "    torch.nn.Conv2d(6, 12, kernel_size=5),\n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.MaxPool2d(2, stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(300, 50), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train:\n",
    "    print(X[0].shape, y[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.006)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0. \n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(axis=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0. \n",
    "\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(axis=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        \n",
    "        print('ep: {}, taken: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}'.format(\n",
    "        ep, time.time() - start, train_loss / train_iters, train_acc / train_passed, \n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "             )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 14.260, train_loss: 0.654350513093015, train_acc: 0.7583166666666666, test_loss: 0.44713825099170207, test_acc: 0.8387\n",
      "ep: 1, taked: 14.265, train_loss: 0.39536155297401104, train_acc: 0.8581833333333333, test_loss: 0.38414958864450455, test_acc: 0.8615\n",
      "ep: 2, taked: 14.011, train_loss: 0.34246235470822517, train_acc: 0.8756833333333334, test_loss: 0.36428055390715597, test_acc: 0.8681\n",
      "ep: 3, taked: 14.736, train_loss: 0.313039660326978, train_acc: 0.8864, test_loss: 0.33981270529329777, test_acc: 0.8773\n",
      "ep: 4, taked: 14.087, train_loss: 0.2902521965985603, train_acc: 0.8930833333333333, test_loss: 0.34157638289034364, test_acc: 0.8763\n",
      "ep: 5, taked: 13.895, train_loss: 0.2758229638033725, train_acc: 0.8992833333333333, test_loss: 0.3408873688429594, test_acc: 0.8778\n",
      "ep: 6, taked: 13.973, train_loss: 0.26465216456575597, train_acc: 0.9030666666666667, test_loss: 0.3417618960142136, test_acc: 0.8769\n",
      "ep: 7, taked: 14.174, train_loss: 0.25281009902345375, train_acc: 0.9069, test_loss: 0.32242021076381205, test_acc: 0.8869\n",
      "ep: 8, taked: 14.164, train_loss: 0.24601534592344407, train_acc: 0.9092166666666667, test_loss: 0.33099741376936437, test_acc: 0.8837\n",
      "ep: 9, taked: 14.376, train_loss: 0.24048723166293287, train_acc: 0.9104, test_loss: 0.32956659235060215, test_acc: 0.8833\n",
      "ep: 10, taked: 14.123, train_loss: 0.2325153333075503, train_acc: 0.9127333333333333, test_loss: 0.34424515105783937, test_acc: 0.8824\n",
      "ep: 11, taked: 14.388, train_loss: 0.22561377312274689, train_acc: 0.91565, test_loss: 0.3279391348361969, test_acc: 0.8862\n",
      "ep: 12, taked: 14.422, train_loss: 0.21996350497641462, train_acc: 0.9175833333333333, test_loss: 0.3373364180326462, test_acc: 0.8868\n",
      "ep: 13, taked: 14.091, train_loss: 0.21831494154448206, train_acc: 0.9177833333333333, test_loss: 0.3339387521147728, test_acc: 0.8877\n",
      "ep: 14, taked: 14.720, train_loss: 0.21419872403778928, train_acc: 0.9202333333333333, test_loss: 0.32103436514735223, test_acc: 0.8951\n",
      "ep: 15, taked: 13.952, train_loss: 0.21087759691984095, train_acc: 0.9208666666666666, test_loss: 0.3285152669996023, test_acc: 0.8909\n",
      "ep: 16, taked: 14.540, train_loss: 0.2082557331374351, train_acc: 0.92175, test_loss: 0.3272572815418243, test_acc: 0.8909\n",
      "ep: 17, taked: 14.090, train_loss: 0.20517902196721827, train_acc: 0.9227166666666666, test_loss: 0.3370016559958458, test_acc: 0.8862\n",
      "ep: 18, taked: 14.246, train_loss: 0.20114960372447968, train_acc: 0.9238666666666666, test_loss: 0.3506529815495014, test_acc: 0.8872\n",
      "ep: 19, taked: 14.348, train_loss: 0.20003631321039606, train_acc: 0.9239666666666667, test_loss: 0.36321740262210367, test_acc: 0.8859\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
