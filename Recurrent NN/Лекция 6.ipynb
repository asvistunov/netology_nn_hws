{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:11:51.143288Z",
     "start_time": "2020-03-12T15:11:49.649354Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:00.685533Z",
     "start_time": "2020-03-12T15:12:00.591616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10368</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>Lisa Simpson: Maggie, look. What's that?</td>\n",
       "      <td>235000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Maggie, look. What's that?</td>\n",
       "      <td>maggie look whats that</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10369</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>Lisa Simpson: Lee-mur. Lee-mur.</td>\n",
       "      <td>237000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Lee-mur. Lee-mur.</td>\n",
       "      <td>lee-mur lee-mur</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10370</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>Lisa Simpson: Zee-boo. Zee-boo.</td>\n",
       "      <td>239000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>Zee-boo. Zee-boo.</td>\n",
       "      <td>zee-boo zee-boo</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10372</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>Lisa Simpson: I'm trying to teach Maggie that ...</td>\n",
       "      <td>245000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>I'm trying to teach Maggie that nature doesn't...</td>\n",
       "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10374</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>Lisa Simpson: It's like an ox, only it has a h...</td>\n",
       "      <td>254000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Simpson Home</td>\n",
       "      <td>It's like an ox, only it has a hump and a dewl...</td>\n",
       "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  episode_id  number  \\\n",
       "0           0  10368          35      29   \n",
       "1           1  10369          35      30   \n",
       "2           2  10370          35      31   \n",
       "3           3  10372          35      33   \n",
       "4           4  10374          35      35   \n",
       "\n",
       "                                            raw_text  timestamp_in_ms  \\\n",
       "0           Lisa Simpson: Maggie, look. What's that?           235000   \n",
       "1                    Lisa Simpson: Lee-mur. Lee-mur.           237000   \n",
       "2                    Lisa Simpson: Zee-boo. Zee-boo.           239000   \n",
       "3  Lisa Simpson: I'm trying to teach Maggie that ...           245000   \n",
       "4  Lisa Simpson: It's like an ox, only it has a h...           254000   \n",
       "\n",
       "   speaking_line  character_id  location_id raw_character_text  \\\n",
       "0           True             9          5.0       Lisa Simpson   \n",
       "1           True             9          5.0       Lisa Simpson   \n",
       "2           True             9          5.0       Lisa Simpson   \n",
       "3           True             9          5.0       Lisa Simpson   \n",
       "4           True             9          5.0       Lisa Simpson   \n",
       "\n",
       "  raw_location_text                                       spoken_words  \\\n",
       "0      Simpson Home                         Maggie, look. What's that?   \n",
       "1      Simpson Home                                  Lee-mur. Lee-mur.   \n",
       "2      Simpson Home                                  Zee-boo. Zee-boo.   \n",
       "3      Simpson Home  I'm trying to teach Maggie that nature doesn't...   \n",
       "4      Simpson Home  It's like an ox, only it has a hump and a dewl...   \n",
       "\n",
       "                                     normalized_text  word_count  \n",
       "0                             maggie look whats that         4.0  \n",
       "1                                    lee-mur lee-mur         2.0  \n",
       "2                                    zee-boo zee-boo         2.0  \n",
       "3  im trying to teach maggie that nature doesnt e...        24.0  \n",
       "4  its like an ox only it has a hump and a dewlap...        18.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:15.820742Z",
     "start_time": "2020-03-12T15:12:15.809523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maggie look whats that',\n",
       " 'lee-mur lee-mur',\n",
       " 'zee-boo zee-boo',\n",
       " 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have',\n",
       " 'its like an ox only it has a hump and a dewlap hump and dew-lap hump and dew-lap',\n",
       " 'you know his blood type how romantic',\n",
       " 'oh yeah whats my shoe size',\n",
       " 'ring',\n",
       " 'yes dad',\n",
       " 'ooh look maggie what is that do-dec-ah-edron dodecahedron']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = df['normalized_text'].tolist()\n",
    "phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:32.809563Z",
     "start_time": "2020-03-12T15:12:32.768140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делаем массив с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:53.641351Z",
     "start_time": "2020-03-12T15:12:53.636757Z"
    }
   },
   "outputs": [],
   "source": [
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:13:58.918002Z",
     "start_time": "2020-03-12T15:13:55.602551Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)\n",
    "for i in range(len(text)):\n",
    "    for j, w in enumerate(text[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:14:24.776980Z",
     "start_time": "2020-03-12T15:14:24.761649Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27,  5, 19, 19, 25,  6,  1, 15, 21, 21, 18,  1,  2,  4,  5, 24, 23,  1,\n",
       "         24,  4,  5, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [15,  6,  6,  0, 27, 17, 22,  1, 15,  6,  6,  0, 27, 17, 22,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [20,  6,  6,  0, 13, 21, 21,  1, 20,  6,  6,  0, 13, 21, 21,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [25, 27,  1, 24, 22, 26, 25,  7, 19,  1, 24, 21,  1, 24,  6,  5,  8,  4,\n",
       "          1, 27,  5, 19, 19, 25,  6,  1, 24,  4,  5, 24,  1,  7,  5, 24, 17, 22,\n",
       "          6,  1,  3, 21,  6, 23,  7, 24,  1,  6,  7,  3,  1,  2],\n",
       "        [25, 24, 23,  1, 15, 25, 18,  6,  1,  5,  7,  1, 21, 16,  1, 21,  7, 15,\n",
       "         26,  1, 25, 24,  1,  4,  5, 23,  1,  5,  1,  4, 17, 27, 10,  1,  5,  7,\n",
       "          3,  1,  5,  1,  3,  6,  2, 15,  5, 10,  1,  4, 17, 27],\n",
       "        [26, 21, 17,  1, 18,  7, 21,  2,  1,  4, 25, 23,  1, 13, 15, 21, 21,  3,\n",
       "          1, 24, 26, 10,  6,  1,  4, 21,  2,  1, 22, 21, 27,  5,  7, 24, 25,  8,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [21,  4,  1, 26,  6,  5,  4,  1,  2,  4,  5, 24, 23,  1, 27, 26,  1, 23,\n",
       "          4, 21,  6,  1, 23, 25, 20,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 25,  7, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [26,  6, 23,  1,  3,  5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [21, 21,  4,  1, 15, 21, 21, 18,  1, 27,  5, 19, 19, 25,  6,  1,  2,  4,\n",
       "          5, 24,  1, 25, 23,  1, 24,  4,  5, 24,  1,  3, 21,  0,  3,  6,  8,  0,\n",
       "          5,  4,  0,  6,  3, 22, 21,  7,  1,  3, 21,  3,  6,  8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set('abcdefghijklmnopqrstuvwxyz')\n",
    "index_to_char = sorted([w for w in chars])\n",
    "char_to_index = {i: k for i, k in zip(index_to_char, np.roll(np.array(index_to_char), 5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'v',\n",
       " 'b': 'w',\n",
       " 'c': 'x',\n",
       " 'd': 'y',\n",
       " 'e': 'z',\n",
       " 'f': 'a',\n",
       " 'g': 'b',\n",
       " 'h': 'c',\n",
       " 'i': 'd',\n",
       " 'j': 'e',\n",
       " 'k': 'f',\n",
       " 'l': 'g',\n",
       " 'm': 'h',\n",
       " 'n': 'i',\n",
       " 'o': 'j',\n",
       " 'p': 'k',\n",
       " 'q': 'l',\n",
       " 'r': 'm',\n",
       " 's': 'n',\n",
       " 't': 'o',\n",
       " 'u': 'p',\n",
       " 'v': 'q',\n",
       " 'w': 'r',\n",
       " 'x': 's',\n",
       " 'y': 't',\n",
       " 'z': 'u'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvbbdz gjjf rcvon ocvo',\n",
       " 'gzz hpm gzz hpm',\n",
       " 'uzz wjj uzz wjj',\n",
       " 'dh omtdib oj ozvxc hvbbdz ocvo ivopmz yjznio ziy rdoc ocz wvmitvmy d rvio czm oj cvqz vgg ocz vyqviovbzn ocvo d ydyio cvqz',\n",
       " 'don gdfz vi js jigt do cvn v cphk viy v yzrgvk cphk viy yzr gvk cphk viy yzr gvk',\n",
       " 'tjp fijr cdn wgjjy otkz cjr mjhviodx',\n",
       " 'jc tzvc rcvon ht ncjz nduz',\n",
       " 'mdib',\n",
       " 'tzn yvy',\n",
       " 'jjc gjjf hvbbdz rcvo dn ocvo yj yzx vc zymji yjyzxvczymji']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = [''.join([char_to_index.get(letter, ' ') for letter in phrase]) for phrase in phrases if type(phrase) is str]\n",
    "codes[:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:32.809563Z",
     "start_time": "2020-03-12T15:12:32.768140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_codes = [[c for c in ph] for ph in codes if type(ph) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:13:58.918002Z",
     "start_time": "2020-03-12T15:13:55.602551Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "Y = torch.zeros((len(text_codes), MAX_LEN), dtype=int)\n",
    "for i in range(len(text_codes)):\n",
    "    for j, w in enumerate(text_codes[i]):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        Y[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27,  5, 19, 19, 25,  6,  1, 15, 21, 21, 18,  1,  2,  4,  5, 24, 23,  1,\n",
       "         24,  4,  5, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [15,  6,  6,  0, 27, 17, 22,  1, 15,  6,  6,  0, 27, 17, 22,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [20,  6,  6,  0, 13, 21, 21,  1, 20,  6,  6,  0, 13, 21, 21,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [25, 27,  1, 24, 22, 26, 25,  7, 19,  1, 24, 21,  1, 24,  6,  5,  8,  4,\n",
       "          1, 27,  5, 19, 19, 25,  6,  1, 24,  4,  5, 24,  1,  7,  5, 24, 17, 22,\n",
       "          6,  1,  3, 21,  6, 23,  7, 24,  1,  6,  7,  3,  1,  2],\n",
       "        [25, 24, 23,  1, 15, 25, 18,  6,  1,  5,  7,  1, 21, 16,  1, 21,  7, 15,\n",
       "         26,  1, 25, 24,  1,  4,  5, 23,  1,  5,  1,  4, 17, 27, 10,  1,  5,  7,\n",
       "          3,  1,  5,  1,  3,  6,  2, 15,  5, 10,  1,  4, 17, 27],\n",
       "        [26, 21, 17,  1, 18,  7, 21,  2,  1,  4, 25, 23,  1, 13, 15, 21, 21,  3,\n",
       "          1, 24, 26, 10,  6,  1,  4, 21,  2,  1, 22, 21, 27,  5,  7, 24, 25,  8,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [21,  4,  1, 26,  6,  5,  4,  1,  2,  4,  5, 24, 23,  1, 27, 26,  1, 23,\n",
       "          4, 21,  6,  1, 23, 25, 20,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 25,  7, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [26,  6, 23,  1,  3,  5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [21, 21,  4,  1, 15, 21, 21, 18,  1, 27,  5, 19, 19, 25,  6,  1,  2,  4,\n",
       "          5, 24,  1, 25, 23,  1, 24,  4,  5, 24,  1,  3, 21,  0,  3,  6,  8,  0,\n",
       "          5,  4,  0,  6,  3, 22, 21,  7,  1,  3, 21,  3,  6,  8]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 13, 13,  3, 20,  1, 19, 11, 11, 14,  1, 22,  8, 12, 21,  7,  1,\n",
       "         21,  8, 12, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [19, 20, 20,  1,  4, 10, 27,  1, 19, 20, 20,  1,  4, 10, 27,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [17, 20, 20,  1,  2, 11, 11,  1, 17, 20, 20,  1,  2, 11, 11,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  4,  1, 21, 27, 24,  3, 25, 13,  1, 21, 11,  1, 21, 20, 12, 16,  8,\n",
       "          1,  4, 12, 13, 13,  3, 20,  1, 21,  8, 12, 21,  1, 25, 12, 21, 10, 27,\n",
       "         20,  1, 26, 11, 20,  7, 25, 21,  1, 20, 25, 26,  1, 22],\n",
       "        [ 3, 21,  7,  1, 19,  3, 14, 20,  1, 12, 25,  1, 11, 23,  1, 11, 25, 19,\n",
       "         24,  1,  3, 21,  1,  8, 12,  7,  1, 12,  1,  8, 10,  4, 18,  1, 12, 25,\n",
       "         26,  1, 12,  1, 26, 20, 22, 19, 12, 18,  1,  8, 10,  4],\n",
       "        [24, 11, 10,  1, 14, 25, 11, 22,  1,  8,  3,  7,  1,  2, 19, 11, 11, 26,\n",
       "          1, 21, 24, 18, 20,  1,  8, 11, 22,  1, 27, 11,  4, 12, 25, 21,  3, 16,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [11,  8,  1, 24, 20, 12,  8,  1, 22,  8, 12, 21,  7,  1,  4, 24,  1,  7,\n",
       "          8, 11, 20,  1,  7,  3, 17, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [27,  3, 25, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [24, 20,  7,  1, 26, 12, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [11, 11,  8,  1, 19, 11, 11, 14,  1,  4, 12, 13, 13,  3, 20,  1, 22,  8,\n",
       "         12, 21,  1,  3,  7,  1, 21,  8, 12, 21,  1, 26, 11,  1, 26, 20, 16,  1,\n",
       "         12,  8,  1, 20, 26, 27, 11, 25,  1, 26, 11, 26, 20, 16]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Смотрим на Embedding и RNN ячейку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:14:15.694973Z",
     "start_time": "2020-03-12T15:14:15.644024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7027, -0.1612,  0.2037,  ...,  1.3908, -0.2074,  0.1426],\n",
       "         [-0.6336,  1.0766,  0.4756,  ..., -0.8878, -1.3892,  1.3777],\n",
       "         [ 0.6949, -1.0634, -3.0977,  ..., -0.4530,  0.5257, -1.9299],\n",
       "         ...,\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313]],\n",
       "\n",
       "        [[-0.6705,  0.4050,  0.0308,  ..., -1.6747, -1.5839, -0.7379],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         ...,\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313]],\n",
       "\n",
       "        [[ 0.6074,  0.1300,  0.3210,  ...,  0.3276,  1.0478, -1.1171],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         ...,\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6658,  1.5055, -1.5476,  ...,  0.6825,  1.2281, -0.8735],\n",
       "         [ 0.6579,  1.1746,  1.8139,  ...,  0.3261, -1.0875,  1.2398],\n",
       "         [ 0.6597,  0.3604, -0.0270,  ...,  0.5830, -0.4678, -1.5044],\n",
       "         ...,\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313]],\n",
       "\n",
       "        [[ 0.7086, -0.2597,  1.1524,  ...,  0.1866,  1.1777,  1.0238],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         [-0.7811,  0.2085,  0.0517,  ...,  0.4223, -1.1501,  0.2354],\n",
       "         ...,\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313],\n",
       "         [ 0.4444,  0.9366,  0.2266,  ...,  0.5080,  0.8971, -0.8313]],\n",
       "\n",
       "        [[-1.3213, -0.8565, -0.4112,  ..., -0.1586,  0.8381,  0.3566],\n",
       "         [-1.3213, -0.8565, -0.4112,  ..., -0.1586,  0.8381,  0.3566],\n",
       "         [ 0.4599, -0.8285, -0.8071,  ...,  0.3100,  0.9533,  0.8313],\n",
       "         ...,\n",
       "         [-1.5925, -0.4507,  1.4416,  ..., -1.6069, -0.3654,  0.4819],\n",
       "         [-0.3925, -0.8849,  0.8152,  ...,  1.5247,  0.5321, -0.3344],\n",
       "         [-1.2904, -0.1674,  1.5364,  ...,  0.4492, -1.9756,  1.0311]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
    "t = embeddings(X[0:10])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:14:48.405046Z",
     "start_time": "2020-03-12T15:14:48.400041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 28]), torch.Size([10, 50]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, X[0:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:18:23.190978Z",
     "start_time": "2020-03-12T15:18:23.180493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 128]), torch.Size([1, 10, 128]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(28, 128, batch_first=True)\n",
    "o, s = rnn(t)\n",
    "o.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:18:35.190131Z",
     "start_time": "2020-03-12T15:18:35.180708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 128]), torch.Size([1, 10, 128]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, s2 = rnn(t, s)\n",
    "o.shape, s2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика. Реализуйте код модели нейронной сети\n",
    "3 слоя - embeding (28), скрытая ячейка (128), полносвязанный из состояния rnn в букву (28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:26:45.716418Z",
     "start_time": "2020-03-12T15:26:45.710937Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        ## Здесь создать слои\n",
    "        self.embed = torch.nn.Embedding(len(CHAR_TO_INDEX), 28)\n",
    "        self.rnn = torch.nn.RNN(28, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, len(INDEX_TO_CHAR))\n",
    "        \n",
    "    def forward(self, sentences, state=None):\n",
    "        ## Здесь применить\n",
    "        embed = self.embed(sentences)\n",
    "        o, s = self.rnn(embed)\n",
    "        out = self.linear(o)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:20:53.260599Z",
     "start_time": "2020-03-12T15:20:53.256979Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:21:01.929404Z",
     "start_time": "2020-03-12T15:21:01.925999Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:22:04.410583Z",
     "start_time": "2020-03-12T15:21:34.734119Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 2.274, Train loss: 1.100\n",
      "Epoch 1. Time: 2.172, Train loss: 1.100\n",
      "Epoch 2. Time: 2.156, Train loss: 1.099\n",
      "Epoch 3. Time: 2.119, Train loss: 1.099\n",
      "Epoch 4. Time: 2.200, Train loss: 1.098\n",
      "Epoch 5. Time: 2.153, Train loss: 1.097\n",
      "Epoch 6. Time: 2.143, Train loss: 1.097\n",
      "Epoch 7. Time: 2.115, Train loss: 1.096\n",
      "Epoch 8. Time: 2.103, Train loss: 1.096\n",
      "Epoch 9. Time: 2.108, Train loss: 1.095\n",
      "Epoch 10. Time: 2.263, Train loss: 1.094\n",
      "Epoch 11. Time: 2.174, Train loss: 1.094\n",
      "Epoch 12. Time: 2.126, Train loss: 1.093\n",
      "Epoch 13. Time: 2.119, Train loss: 1.093\n",
      "Epoch 14. Time: 2.125, Train loss: 1.092\n",
      "Epoch 15. Time: 2.129, Train loss: 1.092\n",
      "Epoch 16. Time: 2.127, Train loss: 1.091\n",
      "Epoch 17. Time: 2.165, Train loss: 1.091\n",
      "Epoch 18. Time: 2.204, Train loss: 1.090\n",
      "Epoch 19. Time: 2.201, Train loss: 1.089\n",
      "Epoch 20. Time: 2.220, Train loss: 1.089\n",
      "Epoch 21. Time: 2.349, Train loss: 1.088\n",
      "Epoch 22. Time: 2.490, Train loss: 1.088\n",
      "Epoch 23. Time: 2.423, Train loss: 1.087\n",
      "Epoch 24. Time: 2.322, Train loss: 1.087\n",
      "Epoch 25. Time: 2.280, Train loss: 1.086\n",
      "Epoch 26. Time: 2.268, Train loss: 1.086\n",
      "Epoch 27. Time: 2.264, Train loss: 1.085\n",
      "Epoch 28. Time: 2.270, Train loss: 1.085\n",
      "Epoch 29. Time: 2.273, Train loss: 1.084\n",
      "Epoch 30. Time: 2.264, Train loss: 1.084\n",
      "Epoch 31. Time: 2.297, Train loss: 1.083\n",
      "Epoch 32. Time: 2.276, Train loss: 1.083\n",
      "Epoch 33. Time: 2.304, Train loss: 1.082\n",
      "Epoch 34. Time: 2.318, Train loss: 1.082\n",
      "Epoch 35. Time: 2.286, Train loss: 1.081\n",
      "Epoch 36. Time: 2.278, Train loss: 1.081\n",
      "Epoch 37. Time: 2.331, Train loss: 1.080\n",
      "Epoch 38. Time: 2.227, Train loss: 1.080\n",
      "Epoch 39. Time: 2.225, Train loss: 1.079\n",
      "Epoch 40. Time: 2.205, Train loss: 1.079\n",
      "Epoch 41. Time: 2.205, Train loss: 1.078\n",
      "Epoch 42. Time: 2.398, Train loss: 1.078\n",
      "Epoch 43. Time: 2.575, Train loss: 1.077\n",
      "Epoch 44. Time: 2.520, Train loss: 1.077\n",
      "Epoch 45. Time: 2.438, Train loss: 1.076\n",
      "Epoch 46. Time: 2.374, Train loss: 1.076\n",
      "Epoch 47. Time: 2.291, Train loss: 1.076\n",
      "Epoch 48. Time: 2.344, Train loss: 1.075\n",
      "Epoch 49. Time: 2.303, Train loss: 1.075\n",
      "Epoch 50. Time: 2.303, Train loss: 1.074\n",
      "Epoch 51. Time: 2.225, Train loss: 1.074\n",
      "Epoch 52. Time: 2.210, Train loss: 1.073\n",
      "Epoch 53. Time: 2.201, Train loss: 1.073\n",
      "Epoch 54. Time: 2.207, Train loss: 1.072\n",
      "Epoch 55. Time: 2.217, Train loss: 1.072\n",
      "Epoch 56. Time: 2.207, Train loss: 1.072\n",
      "Epoch 57. Time: 2.231, Train loss: 1.071\n",
      "Epoch 58. Time: 2.197, Train loss: 1.071\n",
      "Epoch 59. Time: 2.203, Train loss: 1.070\n",
      "Epoch 60. Time: 2.202, Train loss: 1.070\n",
      "Epoch 61. Time: 2.203, Train loss: 1.069\n",
      "Epoch 62. Time: 2.207, Train loss: 1.069\n",
      "Epoch 63. Time: 2.343, Train loss: 1.069\n",
      "Epoch 64. Time: 2.207, Train loss: 1.068\n",
      "Epoch 65. Time: 2.211, Train loss: 1.068\n",
      "Epoch 66. Time: 2.206, Train loss: 1.067\n",
      "Epoch 67. Time: 2.199, Train loss: 1.067\n",
      "Epoch 68. Time: 2.195, Train loss: 1.066\n",
      "Epoch 69. Time: 2.210, Train loss: 1.066\n",
      "Epoch 70. Time: 2.203, Train loss: 1.066\n",
      "Epoch 71. Time: 2.229, Train loss: 1.065\n",
      "Epoch 72. Time: 2.213, Train loss: 1.065\n",
      "Epoch 73. Time: 2.266, Train loss: 1.064\n",
      "Epoch 74. Time: 2.224, Train loss: 1.064\n",
      "Epoch 75. Time: 2.247, Train loss: 1.064\n",
      "Epoch 76. Time: 2.207, Train loss: 1.063\n",
      "Epoch 77. Time: 2.202, Train loss: 1.063\n",
      "Epoch 78. Time: 2.196, Train loss: 1.062\n",
      "Epoch 79. Time: 2.217, Train loss: 1.062\n",
      "Epoch 80. Time: 2.206, Train loss: 1.062\n",
      "Epoch 81. Time: 2.202, Train loss: 1.061\n",
      "Epoch 82. Time: 2.195, Train loss: 1.061\n",
      "Epoch 83. Time: 2.205, Train loss: 1.060\n",
      "Epoch 84. Time: 2.222, Train loss: 1.060\n",
      "Epoch 85. Time: 2.203, Train loss: 1.060\n",
      "Epoch 86. Time: 2.229, Train loss: 1.059\n",
      "Epoch 87. Time: 2.243, Train loss: 1.059\n",
      "Epoch 88. Time: 2.233, Train loss: 1.059\n",
      "Epoch 89. Time: 2.219, Train loss: 1.058\n",
      "Epoch 90. Time: 2.206, Train loss: 1.058\n",
      "Epoch 91. Time: 2.204, Train loss: 1.057\n",
      "Epoch 92. Time: 2.209, Train loss: 1.057\n",
      "Epoch 93. Time: 2.210, Train loss: 1.057\n",
      "Epoch 94. Time: 2.210, Train loss: 1.056\n",
      "Epoch 95. Time: 2.205, Train loss: 1.056\n",
      "Epoch 96. Time: 2.203, Train loss: 1.056\n",
      "Epoch 97. Time: 2.212, Train loss: 1.055\n",
      "Epoch 98. Time: 2.228, Train loss: 1.055\n",
      "Epoch 99. Time: 2.197, Train loss: 1.055\n",
      "Epoch 100. Time: 2.203, Train loss: 1.054\n",
      "Epoch 101. Time: 2.207, Train loss: 1.054\n",
      "Epoch 102. Time: 2.201, Train loss: 1.054\n",
      "Epoch 103. Time: 2.227, Train loss: 1.053\n",
      "Epoch 104. Time: 2.221, Train loss: 1.053\n",
      "Epoch 105. Time: 2.208, Train loss: 1.052\n",
      "Epoch 106. Time: 2.201, Train loss: 1.052\n",
      "Epoch 107. Time: 2.345, Train loss: 1.052\n",
      "Epoch 108. Time: 2.347, Train loss: 1.051\n",
      "Epoch 109. Time: 2.333, Train loss: 1.051\n",
      "Epoch 110. Time: 2.249, Train loss: 1.051\n",
      "Epoch 111. Time: 2.410, Train loss: 1.050\n",
      "Epoch 112. Time: 2.395, Train loss: 1.050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dl/xnf1_vhn33v805qcg32x5hz40000gn/T/ipykernel_22226/2952757751.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_passed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(200):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch_X = X[i * 100:(i + 1) * 100]\n",
    "        batch_Y = Y[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch_X[:, :-1]\n",
    "        Y_batch = batch_Y[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:28:40.363097Z",
     "start_time": "2020-03-12T15:28:40.357998Z"
    }
   },
   "source": [
    "## Практика. Реализуйте код генерации следующей буквы на основе модели\n",
    "Логика такая:\n",
    "    - Сначала кормим в нее буквы из sentence (прогревая состояние)\n",
    "    - Затем пока не получим none (0) берем самую вероятную букву и добавляем ее в sentence\n",
    "    - Повторяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:28:59.592247Z",
     "start_time": "2020-03-12T15:28:59.589338Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sentence():\n",
    "    sentence = ['h', 'e', 'l', 'l', 'o']\n",
    "    # Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [*'hvbbdz']\n",
    "x = torch.zeros((1, len(sentence)), dtype=int)\n",
    "for j, w in enumerate(sentence):\n",
    "    if j >= MAX_LEN:\n",
    "        break\n",
    "    x[0, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maggie'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'maggie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\n",
      "z\n",
      "v\n",
      "v\n",
      "v\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentence)):\n",
    "    letter = x[0][i].reshape(-1, 1)\n",
    "    print( INDEX_TO_CHAR[torch.argmax(model(letter))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:23:13.963511Z",
     "start_time": "2020-03-12T15:22:45.311457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 2.762, Train loss: 1.530\n",
      "helloe l   toaaohutd     toooohun     toooohun     tooo\n",
      "Epoch 1. Time: 2.736, Train loss: 1.519\n",
      "helloe l   toaaohutd     toooohun     toooohun     tooo\n",
      "Epoch 2. Time: 2.729, Train loss: 1.509\n",
      "helloe l n toooah n   toaoooutn     toooohun     tooooh\n",
      "Epoch 3. Time: 2.761, Train loss: 1.500\n",
      "helloe l n toooah n   toaoooutn     toooohun     tooooh\n",
      "Epoch 4. Time: 2.746, Train loss: 1.491\n",
      "helloe l n toooth n  etoaoahnnn     toooohun     tooooh\n",
      "Epoch 5. Time: 2.932, Train loss: 1.483\n",
      "helloe l n toooth n  etoaoahnnn     toooohun     tooooh\n",
      "Epoch 6. Time: 2.804, Train loss: 1.475\n",
      "helloe l n toooth n  etoaoahnnn     tooooounn     toooo\n",
      "Epoch 7. Time: 2.790, Train loss: 1.467\n",
      "helloe l n toooth n  etoaoahnnn     tooooounn     toooo\n",
      "Epoch 8. Time: 3.052, Train loss: 1.459\n",
      "helloe l n toooth n  etoaoahnnn     tooooornn     toooo\n",
      "Epoch 9. Time: 3.189, Train loss: 1.452\n",
      "helloe l n toooth nn eto tr ntheto e  ntraooaennnn     \n"
     ]
    }
   ],
   "source": [
    "for ep in range(10):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers, _ = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
    "    generate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
